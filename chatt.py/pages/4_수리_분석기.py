import streamlit as st
import pandas as pd
from datetime import datetime
from collections import OrderedDict
import os
import json

ë°ì´í„° ë¡œë”© í•¨ìˆ˜
@st.cache_data
def load_topic_db(filepath):
if os.path.exists(filepath):
return pd.read_csv(filepath).fillna('')
return None

@st.cache_data
def load_concepts(files):
combined_concepts = OrderedDict()
for file_path in files:
if os.path.exists(file_path):
try:
with open(file_path, 'r', encoding='utf-8') as f:
data = json.load(f)
for key, value in data.items():
if key not in combined_concepts:
combined_concepts[key] = value
except (FileNotFoundError, json.JSONDecodeError):
pass
return combined_concepts

ê³„ì‚° ë¡œì§
HEAVENLY_STEMS = ["ç”²", "ä¹™", "ä¸™", "ä¸", "æˆŠ", "å·±", "åºš", "è¾›", "å£¬", "ç™¸"]
EARTHLY_BRANCHES = ["å­", "ä¸‘", "å¯…", "å¯", "è¾°", "å·³", "åˆ", "æœª", "ç”³", "é…‰", "æˆŒ", "äº¥"]
ELEMENT_MAP = {'ç”²':'ëª©', 'ä¹™':'ëª©', 'ä¸™':'í™”', 'ä¸':'í™”', 'æˆŠ':'í† ', 'å·±':'í† ', 'åºš':'ê¸ˆ', 'è¾›':'ê¸ˆ', 'å£¬':'ìˆ˜', 'ç™¸':'ìˆ˜', 'å¯…':'ëª©', 'å¯':'ëª©', 'å·³':'í™”', 'åˆ':'í™”', 'è¾°':'í† ', 'æˆŒ':'í† ', 'ä¸‘':'í† ', 'æœª':'í† ', 'ç”³':'ê¸ˆ', 'é…‰':'ê¸ˆ', 'å­':'ìˆ˜', 'äº¥':'ìˆ˜'}
SOLAR_TERMS_INFO = {1: {'name': 'ì†Œí•œ', 'day': 5}, 2: {'name': 'ì…ì¶˜', 'day': 4}, 3: {'name': 'ê²½ì¹©', 'day': 5}, 4: {'name': 'ì²­ëª…', 'day': 4}, 5: {'name': 'ì…í•˜', 'day': 5}, 6: {'name': 'ë§ì¢…', 'day': 5}, 7: {'name': 'ì†Œì„œ', 'day': 7}, 8: {'name': 'ì…ì¶”', 'day': 7}, 9: {'name': 'ë°±ë¡œ', 'day': 7}, 10: {'name': 'í•œë¡œ', 'day': 8}, 11: {'name': 'ì…ë™', 'day': 7}, 12: {'name': 'ëŒ€ì„¤', 'day': 7}}

def get_ganji_from_cycle(cycle_index):
return HEAVENLY_STEMS[cycle_index % 10] + EARTHLY_BRANCHES[cycle_index % 12]

def get_saju_pillars(birth_dt):
year, month, day, hour = birth_dt.year, birth_dt.month, birth_dt.day, birth_dt.hour
ipchun_day = 4
year_for_ganji = year if not (month == 1 or (month == 2 and day &lt; ipchun_day)) else year - 1
year_cycle = (year_for_ganji - 1864) % 60
year_pillar = get_ganji_from_cycle(year_cycle)
term_day = SOLAR_TERMS_INFO[month]['day']
month_for_ganji = month if day >= term_day else (month - 1 if month > 1 else 12)
year_stem_char = year_pillar[0]
month_stem_start_map = {"ç”²å·±": 2, "ä¹™åºš": 4, "ä¸™è¾›": 6, "ä¸å£¬": 8, "æˆŠç™¸": 0}
for k, v in month_stem_start_map.items():
if year_stem_char in k: month_stem_start = v
month_stem_index = (month_stem_start + month_for_ganji - 1) % 10
month_branch_index = (month_for_ganji + 1) % 12
month_pillar = HEAVENLY_STEMS[month_stem_index] + EARTHLY_BRANCHES[month_branch_index]
delta_days = (birth_dt.date() - datetime(1900, 1, 1).date()).days
day_cycle = (delta_days + 46) % 60
day_pillar = get_ganji_from_cycle(day_cycle)
day_stem_char = day_pillar[0]
hour_stem_start_map = {"ç”²å·±": 0, "ä¹™åºš": 2, "ä¸™è¾›": 4, "ä¸å£¬": 6, "æˆŠç™¸": 8}
for k, v in hour_stem_start_map.items():
if day_stem_char in k: hour_stem_start = v
hour_index = (hour + 1) // 2 % 12
hour_stem_index = (hour_stem_start + hour_index) % 10
hour_pillar = HEAVENLY_STEMS[hour_stem_index] + EARTHLY_BRANCHES[hour_index]
return OrderedDict([("ë…„ì£¼", year_pillar), ("ì›”ì£¼", month_pillar), ("ì¼ì£¼", day_pillar), ("ì‹œì£¼", hour_pillar)])

def analyze_suam_force(pillars):
scores = {'ëª©í™”': 0, 'ê¸ˆìˆ˜': 0}
for char in "".join(pillars.values()):
element = ELEMENT_MAP.get(char)
if element in ['ëª©', 'í™”']: scores['ëª©í™”'] += 1
elif element in ['ê¸ˆ', 'ìˆ˜']: scores['ê¸ˆìˆ˜'] += 1
if scores['ëª©í™”'] > scores['ê¸ˆìˆ˜']: return "ëª©í™”(æœ¨ç«)ì„¸ë ¥", "ëª©í™”", scores
elif scores['ê¸ˆìˆ˜'] > scores['ëª©í™”']: return "ê¸ˆìˆ˜(é‡‘æ°´)ì„¸ë ¥", "ê¸ˆìˆ˜", scores
else: return "ì„¸ë ¥ ê· í˜•", "ê· í˜•", scores

def analyze_che_yong(pillars, force_keyword):
if force_keyword == "ê· í˜•": return None, None
che_elements = ['ëª©', 'í™”'] if force_keyword == "ëª©í™”" else ['ê¸ˆ', 'ìˆ˜']
yong_elements = ['ê¸ˆ', 'ìˆ˜'] if force_keyword == "ëª©í™”" else ['ëª©', 'í™”']
che_chars, yong_chars = [], []
for char in list("".join(pillars.values())):
element = ELEMENT_MAP.get(char)
if element in che_elements: che_chars.append(char)
elif element in yong_elements: yong_chars.append(char)
return che_chars, yong_chars

def analyze_suppression_structure(che_chars, yong_chars):
if not che_chars or not yong_chars: return "ì„¸ë ¥ì´ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì³ ì œì••êµ¬ì¡°ë¥¼ ë…¼í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
if len(che_chars) >= 6 and len(yong_chars) &lt;= 2: return "ë‚˜ì˜ ì„¸ë ¥(ì²´)ì´ ìƒëŒ€ ì„¸ë ¥(ìš©)ì„ í¬ìœ„í•˜ì—¬ ì œì••í•˜ëŠ” **ì í¬êµ¬ì¡°(è³Šæ•æ§‹é€ )**ì˜ í˜•íƒœì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
elif len(che_chars) > len(yong_chars): return "ë‚˜ì˜ ì„¸ë ¥(ì²´)ì´ ìƒëŒ€ ì„¸ë ¥(ìš©)ì„ ì œì••í•˜ëŠ” ì¼ë°˜ ì œì••êµ¬ì¡°ì˜ í˜•íƒœì…ë‹ˆë‹¤."
else: return "ìƒëŒ€ ì„¸ë ¥(ìš©)ì´ ê°•í•˜ì—¬ ì œì••ì˜ íš¨ìœ¨ì´ ë‚®ì€ êµ¬ì¡°ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

Streamlit UI
st.set_page_config(page_title="ìˆ˜ì•”ëª…ë¦¬ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ”¬ ìˆ˜ì•”ëª…ë¦¬í•™ í•™ìŠµ ë° ë¶„ì„ê¸°")

topic_df = load_topic_db('Topic DB 216b50e66dba805abdb2ebd9cbd601da.csv')
JSON_FILES = ['concepts_from_doc.json', 'ë¡(ç¥¿)ê³¼ ì›ì‹ (åŸèº«)ì˜ ê°œë… ë° ì‚¬ì£¼ ì ìš© ì‚¬ë¡€.json']
concept_db = load_concepts(JSON_FILES)

with st.form("saju_input_form"):
col1, col2, col3 = st.columns(3)
with col1: st.date_input("ğŸ—“ï¸ ìƒë…„ì›”ì¼", value=datetime(2000, 1, 1), key="birth_date")
with col2: st.time_input("â° íƒœì–´ë‚œ ì‹œê°", value=datetime(2000, 1, 1, 12, 0).time(), key="birth_time")
with col3: st.radio("ğŸš» ì„±ë³„", ("ë‚¨ì", "ì—¬ì"), horizontal=True, key="gender")
submitted = st.form_submit_button("ë¶„ì„ ì‹œì‘í•˜ê¸°", use_container_width=True, type="primary")

if submitted:
birth_datetime = datetime.combine(st.session_state.birth_date, st.session_state.birth_time)
pillars = get_saju_pillars(birth_datetime)

st.markdown("---")
st.subheader("ğŸ“ ì‚¬ì£¼ ì›êµ­")
p_cols = st.columns(4)
for i, (name, val) in enumerate(reversed(list(pillars.items()))):
    p_cols[i].metric(label=name, value=val)

st.markdown("---")
st.subheader("ğŸ¤– ìˆ˜ë¦¬ ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸")

with st.container(border=True):
    st.markdown("#### 1ë‹¨ê³„: ì„¸ë ¥ ë¶„ì„")
    force_text, force_keyword, scores = analyze_suam_force(pillars)
    st.info(f"**ë¶„ì„ ê²°ê³¼:** ëª©í™”ì„¸ {scores['ëª©í™”']}ê°œ, ê¸ˆìˆ˜ì„¸ {scores['ê¸ˆìˆ˜']}ê°œë¡œ, **{force_text}**")
    if st.button("'ì œì••ë°©ì‹' ì´ë¡  ë³´ê¸°", key="force_theory"):
        if concept_db and "ì œì••ë°©ì‹" in concept_db:
            st.markdown(concept_db["ì œì••ë°©ì‹"].get("ì •ì˜", "ê´€ë ¨ ì´ë¡  ì—†ìŒ"))

with st.container(border=True):
    st.markdown("#### 2ë‹¨ê³„: ì²´ìš©(é«”ç”¨) êµ¬ë¶„")
    che_chars, yong_chars = analyze_che_yong(pillars, force_keyword)
    if che_chars:
        st.info(f"- **ë‚˜ì˜ ì£¼ì²´ (ì²´ é«”):** {', '.join(che_chars)} ({len(che_chars)}ê°œ)\n- **ë‚˜ì˜ ì“°ì„ (ìš© ç”¨):** {', '.join(yong_chars)} ({len(yong_chars)}ê°œ)")
    else:
        st.warning("ì„¸ë ¥ì´ ê· í˜•ì„ ì´ë£¨ì–´ ì²´ìš© êµ¬ë¶„ì´ ë¬´ì˜ë¯¸í•©ë‹ˆë‹¤.")
    if st.button("'ì²´ìš©' ì´ë¡  ë³´ê¸°", key="cheyong_theory"):
         if concept_db and "í•´ì„¤" in concept_db:
             st.markdown(concept_db["í•´ì„¤"].get("ì •ì˜", "ê´€ë ¨ ì´ë¡  ì—†ìŒ"))

with st.container(border=True):
    st.markdown("#### 3ë‹¨ê³„: ì œì••êµ¬ì¡° ë¶„ì„")
    structure_result = analyze_suppression_structure(che_chars, yong_chars)
    st.info(f"**ë¶„ì„ ê²°ê³¼:** {structure_result}")
    if st.button("'ì í¬êµ¬ì¡°' ë“± ì´ë¡  ë³´ê¸°", key="structure_theory"):
        if topic_df is not None:
            result_df = topic_df[topic_df['Name'].str.contains("ì œì••ë°©ì‹", na=False)]
            if not result_df.empty:
                st.markdown(result_df.iloc[0]['Description'])