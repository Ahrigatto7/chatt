import streamlit as st
import re
from collections import defaultdict
import pandas as pd
import sqlite3
import os
import json
from fpdf import FPDF
from docx import Document

# === í…ìŠ¤íŠ¸ ì¶”ì¶œ ===
def extract_text(file):
    suffix = file.name.split(".")[-1]
    if suffix == "docx":
        doc = Document(file)
        return "\n".join(p.text for p in doc.paragraphs)
    else:
        return file.read().decode("utf-8")

# === ì •êµí•œ í•´ì„ ê·œì¹™ ì¶”ì¶œê¸° ===
def extract_rules_advanced(text):
    pattern = re.compile(
        r'(.+?)\s*(ê²½ìš°|ì¼ ê²½ìš°|ì´ë¼ë©´|ì´ë©´|ì¼ ë•Œ|ì¸ ê²½ìš°|í–ˆì„ ë•Œ|í•˜ê²Œ ë˜ë©´|í•œë‹¤ë©´|í•  ê²½ìš°|ì‹œ|ë•Œ)\s*[,:]?\s*(.+?)(?:\.|$)'
    )
    rules = {}
    for match in pattern.finditer(text):
        condition = match.group(1).strip()
        connector = match.group(2)
        result = match.group(3).strip()

        condition_clean = clean_clause(condition)
        result_clean = clean_clause(result)

        rules.setdefault(condition_clean, []).append(result_clean)
    return rules

def clean_clause(clause):
    clause = re.sub(r"(ì€ëŠ”ì´ê°€|ì„ë¥¼|ì—|ì—ì„œ|ì˜|ë¡œ|ìœ¼ë¡œ|ë„|ë§Œ|ê³¼|ì™€|ì´ë©°|ì´ë‚˜|í•˜ê³ |ë¶€í„°|ê¹Œì§€)$", "", clause.strip())
    return clause

# === í‚¤ì›Œë“œ ë¶„ì„ ===
def extract_sections(text):
    keywords = ['í˜¼ì¸', 'ê²°í˜¼', 'å†å©š', 'åˆå©š', 'ë°°ìš°ìê¶', 'ë¶€ê¶', 'å¤«æ˜Ÿ', 'å¦»å®®', 'å‰¯å¤«å®®']
    lines = text.splitlines()
    results = []
    current_block = []
    capture = False

    for line in lines:
        if any(kw in line for kw in keywords):
            capture = True
        if capture:
            if line.strip():
                current_block.append(line.strip())
            else:
                if current_block:
                    results.append("\n".join(current_block))
                    current_block = []
                    capture = False
    return results, keywords

def analyze_keywords(results, keywords):
    keyword_hits = defaultdict(list)
    for text in results:
        for kw in keywords:
            if kw in text:
                keyword_hits[kw].append(text)

    df = {
        "í‚¤ì›Œë“œ": [],
        "ë¹ˆë„": [],
        "ì˜ˆì‹œ ì¼ë¶€": []
    }
    for k, v in keyword_hits.items():
        df["í‚¤ì›Œë“œ"].append(k)
        df["ë¹ˆë„"].append(len(v))
        df["ì˜ˆì‹œ ì¼ë¶€"].append(v[0][:100] + "..." if v else "")
    return pd.DataFrame(df), keyword_hits

# === ì €ì¥ ===
def save_text(text, filename):
    with open(filename, "w", encoding="utf-8") as f:
        f.write(text)

def save_json(data, filename):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def save_excel(summary_df, keyword_map, filename):
    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:
        summary_df.to_excel(writer, sheet_name="ìš”ì•½", index=False)
        for kw, texts in keyword_map.items():
            df = pd.DataFrame({kw: texts})
            df.to_excel(writer, sheet_name=kw[:31], index=False)

# === PDF ìƒì„± ===
def generate_pdf_report(filename, rule_data: dict, keyword_summary_df):
    pdf = FPDF()
    pdf.add_page()

    font_path = "NanumGothic.ttf"
    pdf.add_font("Nanum", "", font_path, uni=True)
    pdf.add_font("Nanum", "B", font_path, uni=True)
    pdf.set_font("Nanum", 'B', 16)

    pdf.cell(200, 10, txt="ì‚¬ì£¼ ë¬¸ì„œ ë¶„ì„ ë³´ê³ ì„œ", ln=True, align="C")

    pdf.ln(10)
    pdf.set_font("Nanum", 'B', 12)
    pdf.cell(200, 10, txt="ì¶”ì¶œëœ í•´ì„ ê·œì¹™", ln=True)

    for k, v_list in rule_data.items():
        pdf.set_font("Nanum", 'B', 11)
        pdf.cell(200, 8, txt=f"[{k}]", ln=True)
        pdf.set_font("Nanum", '', 11)
        for v in v_list:
            pdf.multi_cell(0, 6, f"- {v}")

    pdf.add_page()
    pdf.set_font("Nanum", 'B', 12)
    pdf.cell(200, 10, txt="í˜¼ì¸ í‚¤ì›Œë“œ ë¶„ì„ ìš”ì•½", ln=True)

    for i, row in keyword_summary_df.iterrows():
        pdf.set_font("Nanum", '', 11)
        line = f"{row['í‚¤ì›Œë“œ']} ({row['ë¹ˆë„']}íšŒ): {row['ì˜ˆì‹œ ì¼ë¶€']}"
        pdf.multi_cell(0, 6, line)

    pdf.output(filename)

# === DB ì €ì¥ ===
def save_to_db(rules, keyword_map):
    conn = sqlite3.connect("saju_analysis.db")
    cur = conn.cursor()

    cur.execute("""CREATE TABLE IF NOT EXISTS rules (
        id INTEGER PRIMARY KEY AUTOINCREMENT, condition TEXT, result TEXT
    )""")
    cur.execute("""CREATE TABLE IF NOT EXISTS keyword_hits (
        id INTEGER PRIMARY KEY AUTOINCREMENT, keyword TEXT, snippet TEXT
    )""")

    for condition, results in rules.items():
        for result in results:
            cur.execute("INSERT INTO rules (condition, result) VALUES (?, ?)", (condition, result))

    for keyword, snippets in keyword_map.items():
        for snip in snippets:
            cur.execute("INSERT INTO keyword_hits (keyword, snippet) VALUES (?, ?)", (keyword, snip))

    conn.commit()
    conn.close()

# === Streamlit ì•± ===
st.set_page_config(page_title="ğŸ“„ ì‚¬ì£¼ ë¬¸ì„œ ìë™ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ“„ ì‚¬ì£¼ ë¬¸ì„œ ìë™ ë¶„ì„ê¸°")

uploaded_file = st.file_uploader("ğŸ“‚ Word (.docx) ë˜ëŠ” í…ìŠ¤íŠ¸ (.txt) íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["docx", "txt"])

if uploaded_file:
    with st.spinner("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
        text = extract_text(uploaded_file)
        st.success("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
        st.text_area("ğŸ“‘ ì›ë¬¸ ë¯¸ë¦¬ë³´ê¸°", text, height=300)

    if st.button("ğŸ” ë¶„ì„ ì‹œì‘"):
        with st.spinner("ê·œì¹™ ë° í‚¤ì›Œë“œ ë¶„ì„ ì¤‘..."):
            rules = extract_rules_advanced(text)
            blocks, keywords = extract_sections(text)
            df, keyword_map = analyze_keywords(blocks, keywords)

            os.makedirs("output", exist_ok=True)
            save_text(text, "output/raw.txt")
            save_json(rules, "output/rules.json")
            save_excel(df, keyword_map, "output/keywords.xlsx")
            generate_pdf_report("output/report.pdf", rules, df)
            save_to_db(rules, keyword_map)

        st.success("âœ… ë¶„ì„ ë° ì €ì¥ ì™„ë£Œ!")
        st.download_button("ğŸ“¥ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", open("output/report.pdf", "rb"), file_name="ì‚¬ì£¼_ë³´ê³ ì„œ.pdf")
        st.dataframe(df)
