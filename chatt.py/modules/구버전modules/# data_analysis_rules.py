# data_analysis_rules.py

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from mlxtend.frequent_patterns import apriori, association_rules
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# âœ… CSV íŒŒì¼ ê²½ë¡œë¥¼ ì—¬ê¸°ì— ì…ë ¥
DATA_PATH = "your_data.csv"  # ì˜ˆ: "./data/my_dataset.csv"
TARGET_COLUMN = "target_column"  # ì˜ˆ: "Label",
"Category" ë“±

def main():
    # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    print("ğŸ” ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    df = pd.read_csv(DATA_PATH)
    print(df.head())

    # 2. ê¸°ì´ˆ í†µê³„ í™•ì¸
    print("\nğŸ“Š ê¸°ì´ˆ í†µê³„:")
    print(df.describe())
    print(df.info())

    # 3. ê²°ì¸¡ì¹˜ ì œê±°
    df = df.dropna()
    print("\nâœ… ê²°ì¸¡ì¹˜ ì œê±° ì™„ë£Œ")

    # 4. ì‹œê°í™” (í˜ì–´í”Œë¡¯ & ìƒê´€ í–‰ë ¬)
    sns.pairplot(df)
    plt.show()

    plt.figure(figsize=(10,
8))
    sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
    plt.title("Correlation Matrix")
    plt.show()

    # 5. ì—°ê´€ ê·œì¹™ ë¶„ì„ (ì´ì§„í™”ëœ ë°ì´í„°ì¼ ê²½ìš° ì‚¬ìš©)
    # print("\nğŸ“Œ ì—°ê´€ ê·œì¹™ ë¶„ì„:")
    # frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)
    # rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1)
    # print(rules[
    ['antecedents', 'consequents', 'support', 'confidence', 'lift'
    ]
])

    # 6. ê²°ì • íŠ¸ë¦¬ë¡œ ê·œì¹™ ì¶”ì¶œ
    print("\nğŸŒ² ê²°ì • íŠ¸ë¦¬ ê·œì¹™ í•™ìŠµ ì¤‘...")

    # ë¬¸ìì—´ ì¸ì½”ë”©
    label_encoders = {}
    for col in df.select_dtypes(include='object'):
        le = LabelEncoder()
        df[col
] = le.fit_transform(df[col
])
        label_encoders[col
] = le

    if TARGET_COLUMN not in df.columns:
        print(f"âŒ ì˜¤ë¥˜: '{TARGET_COLUMN}' ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        return

    X = df.drop(TARGET_COLUMN, axis=1)
    y = df[TARGET_COLUMN
]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = DecisionTreeClassifier(max_depth=3)
    model.fit(X_train, y_train)

    plt.figure(figsize=(16,
8))
    plot_tree(model, feature_names=X.columns, class_names=True, filled=True)
    plt.title("Decision Tree Rules")
    plt.show()

    print("âœ… ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
