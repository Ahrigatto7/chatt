import streamlit as st
import pandas as pd
import json
import os

DB_PATH = "knowledge_base.json"

def load_knowledge_json():
    if os.path.exists(DB_PATH) and os.path.getsize(DB_PATH) > 0:
        with open(DB_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def flatten_knowledge_json(json_db):
    """ì§€ì‹ì„¼í„° JSON â†’ DataFrame(ë¬¸ë‹¨ë³„)"""
    data = []
    for main_topic, topic_data in json_db.items():
        for sub_key, sub in topic_data.get("sub_topics", {}).items():
            d = {
                "ëŒ€ì£¼ì œ": main_topic,
                "ë¬¸ë‹¨ID": sub_key,
                "ë‚´ìš©": sub.get("content", ""),
                "ì¹´í…Œê³ ë¦¬": sub.get("category", ""),
                "íƒœê·¸": sub.get("tags", ""),
                "ë¦¬ë·°": sub.get("review", ""),
                "ë“±ë¡ì¼": sub.get("registered_at", "")
            }
            data.append(d)
    return pd.DataFrame(data)

# ----- Streamlit UI -----
st.set_page_config(page_title="ì§€ì‹ì„¼í„° íƒìƒ‰/ê²€ìƒ‰/í†µê³„", layout="wide")
st.title("ğŸ“š ì§€ì‹ì„¼í„° íƒìƒ‰/ê²€ìƒ‰/í†µê³„")

json_db = load_knowledge_json()
df = flatten_knowledge_json(json_db)
if df.empty:
    st.info("ì•„ì§ ë“±ë¡ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ---- 1. íƒìƒ‰/í•„í„° ----
col1, col2, col3 = st.columns(3)
with col1:
    main_topics = ["ì „ì²´"] + sorted(df['ëŒ€ì£¼ì œ'].unique())
    topic = st.selectbox("ëŒ€ì£¼ì œ", main_topics)
with col2:
    cats = ["ì „ì²´"] + sorted(df['ì¹´í…Œê³ ë¦¬'].unique())
    cat = st.selectbox("ì¹´í…Œê³ ë¦¬", cats)
with col3:
    kw = st.text_input("í‚¤ì›Œë“œ(ë‚´ìš©/íƒœê·¸/ë¦¬ë·° í¬í•¨ ê²€ìƒ‰)")

filtered = df.copy()
if topic != "ì „ì²´":
    filtered = filtered[filtered['ëŒ€ì£¼ì œ'] == topic]
if cat != "ì „ì²´":
    filtered = filtered[filtered['ì¹´í…Œê³ ë¦¬'] == cat]
if kw:
    f1 = filtered['ë‚´ìš©'].str.contains(kw, case=False, na=False)
    f2 = filtered['íƒœê·¸'].str.contains(kw, case=False, na=False)
    f3 = filtered['ë¦¬ë·°'].str.contains(kw, case=False, na=False)
    filtered = filtered[f1 | f2 | f3]

st.markdown(f"#### ê²€ìƒ‰ ê²°ê³¼ ({len(filtered)}ê±´)")
st.dataframe(filtered, use_container_width=True)

# ---- 2. ìƒì„¸/í¸ì§‘ ----
if not filtered.empty:
    sel_idx = st.number_input("ìƒì„¸ë³´ê¸°/í¸ì§‘í•  í–‰ ë²ˆí˜¸", min_value=0, max_value=len(filtered)-1, value=0)
    row = filtered.iloc[sel_idx]
    st.markdown(f"**ë¬¸ë‹¨ID**: {row['ë¬¸ë‹¨ID']}")
    content = st.text_area("ë‚´ìš©", row['ë‚´ìš©'], height=100, key="edit_content")
    category = st.text_input("ì¹´í…Œê³ ë¦¬", row['ì¹´í…Œê³ ë¦¬'], key="edit_cat")
    tags = st.text_input("íƒœê·¸(ì‰¼í‘œ)", row['íƒœê·¸'], key="edit_tags")
    review = st.text_area("ë¦¬ë·°", row['ë¦¬ë·°'], height=60, key="edit_review")
    if st.button("ìˆ˜ì • ì €ì¥"):
        # JSON íŒŒì¼ ì§ì ‘ ìˆ˜ì •(ë¬¸ë‹¨IDë¡œ ê²€ìƒ‰)
        db = load_knowledge_json()
        main_topic = row['ëŒ€ì£¼ì œ']
        docid = row['ë¬¸ë‹¨ID']
        db[main_topic]["sub_topics"][docid]['content'] = content
        db[main_topic]["sub_topics"][docid]['category'] = category
        db[main_topic]["sub_topics"][docid]['tags'] = tags
        db[main_topic]["sub_topics"][docid]['review'] = review
        with open(DB_PATH, 'w', encoding='utf-8') as f:
            json.dump(db, f, ensure_ascii=False, indent=2)
        st.success("ìˆ˜ì • ì €ì¥ ì™„ë£Œ! ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")

# ---- 3. í†µê³„/ì°¨íŠ¸ ----
st.subheader("ì¹´í…Œê³ ë¦¬/íƒœê·¸ë³„ í†µê³„")
col4, col5 = st.columns(2)
with col4:
    st.bar_chart(df['ì¹´í…Œê³ ë¦¬'].value_counts())
with col5:
    tags_series = df['íƒœê·¸'].str.split(',').explode().str.strip()
    tag_counts = tags_series.value_counts()
    st.bar_chart(tag_counts[tag_counts.index != ''].head(10))

st.subheader("ìµœê·¼ ë“±ë¡/ìˆ˜ì • ë¬¸ë‹¨")
recent = df.sort_values("ë“±ë¡ì¼", ascending=False).head(10)
st.table(recent[["ëŒ€ì£¼ì œ","ì¹´í…Œê³ ë¦¬","ë‚´ìš©","íƒœê·¸","ë¦¬ë·°","ë“±ë¡ì¼"]])
